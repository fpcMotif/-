{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "answer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fpcMotif/-/blob/master/Twiiter_Analysis.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jfwazvZmrYWO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Marketing and Business Analytics Individual Assignment\n",
        "\n",
        "1. This assignment accounts for 22% of your final mark.\n",
        "    - 15% from the Marketing component\n",
        "    - 7% from the Business Analytics component\n",
        "1. This is an individual assignment.\n",
        "2. The assignment is due before **17:00 26th October 2018**. The late penalty for the assignment is 10% of the assigned mark per day, starting after 5pm on the due date. The closing date **5pm 2nd November 2018** is the last date on which an assessment will be accepted for marking. \n",
        "3. Please only include your student ID in the submitted report, and do **NOT** include your name.\n",
        "\n",
        "## Background\n",
        "\n",
        "You are employed as a Data Scientist at a telecommunications company. One of the biggest issues facing the company is minimising customer churn. Customer churn is when a customer changes provider. The business is interested in analysing and predicting churn since the cost of acquiring new customers is higher than retaining existing customers.\n",
        "\n",
        "This is particularly problematic for the telecommunications industry as changing telecommunications provider is relatively easy. There are also a large number of price competitive providers to choose from, which encourages churning. \n",
        "\n",
        "Your job is to help the marketing department to undertake the following:\n",
        "- Investigate why and which customers churn\n",
        "- Discover retention oppurtunities and strategies\n",
        "- Identify current customers that are likely to churn so that the retention strategy can be applied\n",
        "- Identify potential customers so that the incentive strategy can be applied\n",
        "\n",
        "## Files\n",
        "\n",
        "Part 1:\n",
        "- churn_survey.json\n",
        "\n",
        "Part 2:\n",
        "- tweets.db\n",
        "\n",
        "\n",
        "## Submission Instructions\n",
        "\n",
        "This assessment will be automatically marked. Any deviation from the stated output form will be marked as an incorrect answer. It is your responsibility to check that the output matches the given template or example for each question.\n",
        "\n",
        "#### What to Submit\n",
        "\n",
        "Submit only your .ipynb file. You can choose to use this file as a template OR start from scratch. Just make sure that running your notebook generates all the answers!\n",
        "\n",
        "#### Filename\n",
        "\n",
        "The filename must be \"BUSS6002_MKBA_STUDENTID.ipynb\"\n",
        "\n",
        "#### Loading the data files when marking\n",
        "\n",
        "We will run your notebook in the same directory as the data files. We will assume the original file names.\n",
        "\n",
        "#### Output\n",
        "\n",
        "The output for each question should be saved to the same directory as the notebook.\n",
        "\n",
        "#### Checking the format of your output files\n",
        "\n",
        "We have created ED Challenges for each question. The challenges will tell you if the FORMAT of your output file is correct. It does not tell you if your answer is correct. Please test your output files on Ed before submitting your assignment.\n",
        "\n",
        "#### Timeout\n",
        "\n",
        "We will automatically run your notebook. Each notebook will be given a maximum of 1 minute to be completed. Please ensure any model training or optimisation will be easily completed in this time frame.\n",
        "\n",
        "## Marking Criteria\n",
        "1. Correctness of results"
      ]
    },
    {
      "metadata": {
        "id": "QUoDAt8RrYWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set your Student ID here"
      ]
    },
    {
      "metadata": {
        "id": "Y7dWaVgTrYWR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "YOURSTUDENTID =460088936"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vJ4_mHoJrYWU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Function"
      ]
    },
    {
      "metadata": {
        "id": "zbiEHJ-YrYWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This function is used to save answers with a non-tabular output\n",
        "def write_txt(student_id, part_number, data):\n",
        "    file = open(\"ID_{0}_Q_{1}.txt\".format(student_id, part_number), 'w')\n",
        "    file.write(data)\n",
        "    file.close()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCAH8xkbrYWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Understanding Churn and Identifying Retention Strategies (20 Marks)\n",
        "\n",
        "## Data\n",
        "\n",
        "The marketing team has collected information from a subset of current and past customers. To understand why customers churn and identify why customers have churned use the ``churn_survey.json`` file.\n",
        "\n",
        "### Data Dictionary\n",
        "\n",
        "| Variable  | Description  |\n",
        "|---|---|\n",
        "| Churn  | Whether the customer churned or not |\n",
        "| Contract  | The contract term of the customer |\n",
        "| Dependents  | Whether the customer has dependents or not |\n",
        "| DeviceProtection  | Whether the customer has purchased the device protection service or not |\n",
        "| Gender  | Customer gender |\n",
        "| InternetService  | Customer’s internet service type |\n",
        "| MonthlyCharges  | The amount charged to the customer monthly |\n",
        "| MultipleLines  | Whether the customer has multiple lines or not |\n",
        "| OnlineBackup  | Whether the customer has purchased the additional online backup service or not |\n",
        "| OnlineSecurity  | Whether the customer has purchased the additional online security service or not |\n",
        "| PaperlessBilling  | Whether the customer has paperless billing or not |\n",
        "| Partner  | Whether the customer has a partner or not |\n",
        "| PaymentMethod  | The customer’s payment method |\n",
        "| PhoneService  | Whether the customer has a phone service or not |\n",
        "| SeniorCitizen  | Whether the customer is a senior citizen or not |\n",
        "| StreamingMovies  | Whether the customer has purchased the additional streaming movie service or not |\n",
        "| StreamingTV  | Whether the customer has purchased the additional streaming TV service or not |\n",
        "| TechSupport  | Whether the customer has purchased the additional tech support service or not |\n",
        "| Tenure  | Number of months the customer has stayed with the company |\n",
        "| TotalCharges  | The total amount charged to the customer |\n"
      ]
    },
    {
      "metadata": {
        "id": "cMB5_INbrYWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use this area to load the data\n",
        "#Read the .json document\n",
        "#Import relevant package function\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open(\"churn_survey.json\",\"r\") as load_f:\n",
        "     load_dict = json.load(load_f)\n",
        "# load the file in 'list' type\n",
        "# 把导入的数据转换成dataframe 格式，方便之后使用\n",
        "B = pd.DataFrame(load_dict)\n",
        "#检查导入的正确性\n",
        "#这句可以删掉，不用非得留\n",
        "# churn 表示离开， no 表示是我们的用户\n",
        "B.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2AcyFP8rYWd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsAL6nbrrYWf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "\n",
        "### 1.1 What is the most popular payment method? (1 Mark)\n",
        "\n",
        "Output your answer as a .txt file containing the name of the most popular payment method.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_1.txt"
      ]
    },
    {
      "metadata": {
        "id": "mn47i54crYWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#选取想看的数据名称\n",
        "#使用data dictionary, 得到名字为paymentmethod\n",
        "#统计各个category 的数量\n",
        "B['PaymentMethod'].value_counts()\n",
        "#把结果保存为method_name\n",
        "\n",
        "method_name = B['PaymentMethod'].value_counts().index[0]\n",
        "\n",
        "#导出结果为txt 文件\n",
        "# This will save your answer to a .txt file\n",
        "write_txt(YOURSTUDENTID, \"1_1\", method_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPKMFr1UrYWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-zL-FYzrYWn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 What is the mean amount spent per month for the churn and non-churn customers? (1 Mark)\n",
        "\n",
        "Output your answer as a .csv file with the following format to four decimal places. DO NOT include the $ sign.\n",
        "\n",
        "| Churn  | MonthlyCharges  |\n",
        "|---|---|\n",
        "| No  | 00.0000  |\n",
        "| Yes  |  00.0000 |\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_2.csv"
      ]
    },
    {
      "metadata": {
        "id": "0-Tm6glBrYWn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#选取想要查看的变量名称\n",
        "#使用data dic,得到的名字为monthlyCharges 平均来看花了多少钱\n",
        "#计算该变量在不同class 下的均值，使用groupby 来区分不同的class\n",
        "Question1_2 = B.groupby(['Churn']).mean()\n",
        "Question1_2 = Question1_2. reset_index() #\n",
        "Question1_2_MonthlyCharges = Question1_2.iloc [:,:2]\n",
        "#整合结果为dataframe\n",
        "answer = pd.DataFrame(Question1_2_MonthlyCharges)\n",
        "\n",
        "#调整精确度到4位小数\n",
        "answer = answer.round(4)\n",
        "\n",
        "#导出结果为 csv\n",
        "answer.to_csv('ID_{}_Q_1_2.csv'.format(YOURSTUDENTID), index=False) # false表示不包含前面的0 和1\n",
        "\n",
        "#记得去掉index\n",
        "answer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KHdm4rcvrYWs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "waOQTb0VrYWu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Question1_2 = B.groupby(['Churn']).mean()\n",
        "\n",
        "\n",
        "answer = answer.round(4)\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UhQy6Il7rYWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Question1_2 = B.groupby(['Churn']).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NF57W2WKrYW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EtvGO97krYW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyOoN6bnrYW4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 What is the standard deviation of amount spent per month for the churn and non-churn customers? (1 Mark)\n",
        "\n",
        "Output your answer as a .csv file with the following format to four decimal places. DO NOT include the $ sign.\n",
        "\n",
        "| Churn  | MonthlyCharges  |\n",
        "|---|---|\n",
        "| No  | 00.0000  |\n",
        "| Yes  |  00.0000 |\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_3.csv"
      ]
    },
    {
      "metadata": {
        "id": "1SYKNi3ZrYW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#选取想要查看的变量名称：\n",
        "#使用data dic,得到的名字为: MonthlyCharges\n",
        "\n",
        "#计算该变量在不同class 下的均值，使用groupby 来区分不同的class\n",
        "Question1_3 = B.groupby(['Churn']).std()\n",
        "Question1_3 = Question1_3. reset_index()\n",
        "Question1_3_MonthlyCharges = Question1_3.iloc [:,:2]\n",
        "\n",
        "#整合结果为dataframe\n",
        "\n",
        "answer = pd.DataFrame(Question1_3_MonthlyCharges)\n",
        "\n",
        "#调整精确度到4位小数\n",
        "answer = answer.round(4)\n",
        "\n",
        "#导出结果为 csv\n",
        "answer.to_csv('ID_{}_Q_1_3.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFlkAQZGrYW7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#计算该变量在不同class 下的均值，使用groupby 来区分不同的class\n",
        "Question1_3 = B.groupby(['Churn']).std()\n",
        "Question1_3 = Question1_3. reset_index()\n",
        "Question1_3_MonthlyCharges = Question1_3.iloc [:,:2]\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3IuZxe0SrYW-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 What is the percentage of contract type for the churn and non-churn customers (2 Marks)\n",
        "\n",
        "Output your answer as a .csv file with the following format to two decimal places. Do not include the % symbol.\n",
        "\n",
        "| Churn  | Month-to-month  | One year | Two year |\n",
        "|---|---|---|---|\n",
        "| No  | 00.00  |00.00  |00.00  |\n",
        "| Yes  |  00.00 |00.00  |00.00  |\n",
        "\n",
        "This percentage should be relative to the churn status NOT the entire sample i.e. the top left cell is the percentage of customers on month-to-month contracts who didn't churn.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_4.csv"
      ]
    },
    {
      "metadata": {
        "id": "NozgrsTxrYW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#先找到目标变量\n",
        "#做groupyby, 聚合数值为‘计数’\n",
        "#1. 得到不同churn 状态下的人数\n",
        "B14=B.groupby(['Churn','Contract']).agg({'Contract':'count'})\n",
        "\n",
        "#2. 再 groupby 一次，得到不同churn 状态下各种contract 人数\n",
        "contract = B.groupby(['Churn']).agg({'Contract':'count'})\n",
        "#设置分子为contract 状态，分母为churn 转态\n",
        "#想出得到百分比\n",
        "Question1_4=B14.div(contract,level = 'Churn')*100\n",
        "data = [['No']+Question1_4['Contract'].tolist()[:3],\n",
        "       ['Yes']+Question1_4['Contract'].tolist()[3:]]\n",
        "col = ['Churn', 'Month-to-Month','One year','Two year']# column name ， 后面是contract 三种类型\n",
        "Question1_4 = pd.DataFrame(data,columns = col)\n",
        "answer = pd.DataFrame(Question1_4).round(2)\n",
        "answer.to_csv('ID_{}_Q_1_4.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DlMkqfk9rYXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bh-_kn08rYXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXxxXHJhrYXG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Which feature and value is most correlated with MonthlyCharges? (2.5 Marks)\n",
        "\n",
        "Output your answer as a .csv file with the following format containing the most correlated feature name and value.\n",
        "\n",
        "| Feature  | Value  |\n",
        "|---|---|---|---|\n",
        "| FEATURE_NAME  | FEATURE_VALUE  |\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_5.csv"
      ]
    },
    {
      "metadata": {
        "id": "HXAuLc60rYXG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#计算各个变量和MonthlyCharges 的correlation\n",
        "B.corr()\n",
        "\n",
        "#对correlation 进行手动或自动排序\n",
        "\n",
        "#结果整合和dataframe, 调整格式如上图\n",
        "Question1_5 = {'Feature':'TotalCharges','Value':['0.6460']}\n",
        "answer = pd.DataFrame(Question1_5).round(4)\n",
        "\n",
        "#结果导出来为csv文件\n",
        "answer.to_csv('ID_{}_Q_1_5.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p_Q4MIbIrYXJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qb4KiHLhrYXL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9eBKgEOGrYXP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.6 What is the count, mean, std, min, quartiles and max of time before a customer churns? (2.5 Marks)\n",
        "\n",
        "Output your result as a two column .csv with the following format to four decimal places\n",
        "\n",
        "|   | Tenure  |\n",
        "|---|---|\n",
        "| count | 0.0 |\n",
        "| mean  | 0.0 |\n",
        "| std   | 0.0 |\n",
        "| min  | 0.0 |\n",
        "| 25%  | 0.0 |\n",
        "| 50%  | 0.0 |\n",
        "| 75%  | 0.0 |\n",
        "| max  | 0.0 |\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_6.csv"
      ]
    },
    {
      "metadata": {
        "id": "K1V3cGDArYXQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gYCHSEySrYXT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pbFEFDYRrYXV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# WRITE YOUR CODE HERE\n",
        "#查看目标变量的统计描述  描述性统计分析\n",
        "B.describe().iloc[:,1]\n",
        "Question1_6 = B[B['Churn'] == 'No'].describe().iloc[:, 1]\n",
        "\n",
        "#保存结果为dataframe格式\n",
        "#调整精确值到1位小数\n",
        "answer = pd.DataFrame(Question1_6).round(4)\n",
        "#导出为csv文件\n",
        "answer.to_csv('ID_{}_Q_1_6.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwCvwjp2rYXX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.7 What is the proportion of purchase for each account addon for male and female customers? (4 Marks)\n",
        "\n",
        "Output your result as a .csv with the following format to four decimal places\n",
        "\n",
        "| Gender  | ADDON1  | ADDON2  | ... |\n",
        "|---|---|---|\n",
        "| Female  | 0.0000  | 0.0000  | .. |\n",
        "| Male  |  0.0000 | 0.0000  | .. |\n",
        "\n",
        "Please use the original name of the addon from the data. You must use your understanding of the data and the problem to determine where you can find this information in the dataset.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_7.csv"
      ]
    },
    {
      "metadata": {
        "id": "APxuMvtArYXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#根据data dic 描述\n",
        "addon = ['OnlineBackup', 'OnlineSecurity', 'StreamingMovies', 'StreamingTV', 'TechSupport']\n",
        "addon_gender = ['Gender'] + addon\n",
        "#对dataframe 做groupby, 聚合结果为count\n",
        "B_addon = B.loc[:, addon_gender]\n",
        "\n",
        "\n",
        "Question1_7_gender = B_addon.groupby(['Gender']).agg('count')\n",
        "#创建空白列表，用于储存计算结果\n",
        "Question1_7_female = ['Female']\n",
        "Question1_7_male = ['Male']#第一个值创建为female,male\n",
        "\n",
        "# forloop 5个不同类别\n",
        "for i in range(5):\n",
        "    group = B.groupby(['Gender', addon_gender[i+1]]).agg({addon_gender[i+1]:'count'})#对addon 数数\n",
        "    \n",
        "#分别计算每一类的分子分母，想出得到percentage\n",
        "\n",
        "    female = 100 * int(group.iloc[2])/Question1_7_gender.iloc[0,i]\n",
        "#iloc根据位置来选择行或者列，loc 根据名字来选择行或者列\n",
        "    male = 100 * int(group.iloc[5])/Question1_7_gender.iloc[1,i]\n",
        "#把新的结果增加到列表中进行保存\n",
        "    Question1_7_female.append(female)\n",
        "    Question1_7_male.append(male)\n",
        "#把结果调整， 储存为data frame\n",
        "data = [Question1_7_female, Question1_7_male]\n",
        "col = ['Gender'] + addon_gender[1:]\n",
        "Question1_7 = pd.DataFrame(data,columns = col)\n",
        "\n",
        "#调整精确到4位小数\n",
        "answer = pd.DataFrame(Question1_7).round(4)\n",
        "\n",
        "#导出为csv 文件\n",
        "\n",
        "answer.to_csv('ID_{}_Q_1_7.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoQh34bQrYXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "-VuKkW6lrYXc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0DQL8H-urYXe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.8 Of the listed account addons, which addon/addons could be offered to churning customers for free or at a discounted rate in order to best retain them? (6 Marks)\n",
        "\n",
        "Output your file as a single column .csv with the following format\n",
        "\n",
        "| Addon  |\n",
        "|---|\n",
        "| ADDONX  | \n",
        "| ADDONY  |\n",
        "| ...  | \n",
        "\n",
        "where ADDONX is the name of one addon that you suggest. You must suggest at least 1 account addon up the total amount of addons listed in the dataset. You must exercise your best judgement and supporting evidence from the data to obtain a list of suggested addons. These addons should reflect the interests of the churning customers, i.e. which addons they actually care about.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_1_8.csv"
      ]
    },
    {
      "metadata": {
        "id": "Ckj-OczFrYXf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n",
        "#先想好自己筛选的依据 还在用的人办了业务的，\n",
        "addon_churn = ['Churn'] + addon\n",
        "#计算相关数据\n",
        "#定义变量\n",
        "\n",
        "B_addon = B.loc[:, addon_churn]\n",
        "Question1_8_churn = B_addon.groupby(['Churn']).agg('count')\n",
        "#创建空白list用于存储计算结果\n",
        "Question1_8_NN = []\n",
        "Question1_8_NY = []\n",
        "Question1_8_YN = []\n",
        "Question1_8_YY = []\n",
        "\n",
        "for i in range (5):\n",
        "    group = B.groupby(['Churn', addon_churn[i+1]]).agg({addon_churn[i+1]: 'count'})\n",
        "#还在用的人中没办业务的\n",
        "    NN = int(group.iloc[0])/Question1_8_churn.iloc[0,i]\n",
        "#还在用的人中办了业务的\n",
        "    NY = int(group.iloc[2])/Question1_8_churn.iloc[0,i]\n",
        "#没在用了的人中没办业务的\n",
        "    YN = int(group.iloc[3])/Question1_8_churn.iloc[0,i]\n",
        "#没在用的人中办了业务的\n",
        "    YY = int(group.iloc[5])/Question1_8_churn.iloc[0,i]\n",
        "#储存计算结果\n",
        "    Question1_8_NN.append(NN)\n",
        "    Question1_8_NY.append(NY)\n",
        "    Question1_8_YN.append(YN)\n",
        "    Question1_8_YY.append(YY)\n",
        "#寻找合理的展现方式（图或者表）\n",
        "data = [Question1_8_NN, Question1_8_NY, Question1_8_YN, Question1_8_YY]\n",
        "col = addon_churn[1:]\n",
        "index = ['NO churn_NO addon', 'No churn_addon', 'churn_No addon', 'churn_addon']\n",
        "Question1_8 = pd.DataFrame(data, columns = col, index = index)\n",
        "#给出结论并提供理由\n",
        "#？？？？\n",
        "\n",
        "\n",
        "#把结果调整，存储为dataframe\n",
        "addon_name = {'Addon':['OnlineSecurity', 'StreamingTV']}\n",
        "answer = pd.DataFrame(Question1_8).round(4)\n",
        "#导出为csv文件\n",
        "answer.to_csv('ID_{}_Q_1_8.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer\n",
        "#没在用这家服务，没试过这个服务， 退出了并且没有这个服务， 还在用还订了这个增值服务，差值最大\n",
        "#还在用的人中办了这个业务，没有在用的人办的少的\n",
        "#churn 意思是leaving the serivce\n",
        " #no churn means using the service "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_TyW3ELrYXh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "addon_churn = ['Churn'] + addon\n",
        "#计算相关数据\n",
        "#定义变量\n",
        "\n",
        "B_addon = B.loc[:, addon_churn]\n",
        "Question1_8_churn = B_addon.groupby(['Churn']).agg('count')\n",
        "#创建空白list用于存储计算结果\n",
        "Question1_8_NY = []\n",
        "for i in range (5):\n",
        "    group = B.groupby(['Churn', addon_churn[i+1]]).agg({addon_churn[i+1]: 'count'})\n",
        "    NY = int(group.iloc[2])/Question1_8_churn.iloc[0,i]\n",
        "    Question1_8_NY.append(NY)\n",
        "data = [Question1_8_NY]\n",
        "col = addon_churn[1:]\n",
        "index = ['No churn_addon']\n",
        "Question1_8 = pd.DataFrame(data, columns = col, index = index)\n",
        "#把结果调整，存储为dataframe\n",
        "addon_name = {'Addon':['OnlineSecurity', 'StreamingTV']}\n",
        "answer = pd.DataFrame(Question1_8).round(4)\n",
        "#导出为csv文件\n",
        "answer.to_csv('ID_{}_Q_1_8.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wqIMFi8erYXj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "addon_name = {'Addon':['StreamingTV','StreamingMovies','OnlineBackup','TechSupport','OnlineSecurity']}\n",
        "answer = pd.DataFrame(addon_name).round(4)\n",
        "answer.to_csv('ID_{}_Q_1_8.csv'.format(YOURSTUDENTID), index=False)\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "osPTu7x6rYXm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "addon_churn = ['Churn'] + addon\n",
        "#计算相关数据\n",
        "#定义变量\n",
        "\n",
        "B_addon = B.loc[:, addon_churn]\n",
        "Question1_8_churn = B_addon.groupby(['Churn']).agg('count')\n",
        "#创建空白list用于存储计算结果\n",
        "Question1_8_NY = []\n",
        "for i in range (5):\n",
        "    group = B.groupby(['Churn', addon_churn[i+1]]).agg({addon_churn[i+1]: 'count'})\n",
        "    NY = int(group.iloc[2])\n",
        "    Question1_8_NY.append(NY)\n",
        "data = [Question1_8_NY]\n",
        "col = addon_churn[1:]\n",
        "index = ['No churn_addon']\n",
        "Question1_8 = pd.DataFrame(data, columns = col, index = index)\n",
        "answer = pd.DataFrame(Question1_8).round(4)\n",
        "#把结果调整，存储为dataframe\n",
        "\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQxogALYrYXq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "loryjZKjrYXs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "names = ['StreamingTV','StreamingMovies','OnlineBackup','TechSupport','OnlineSecurity']\n",
        "x = range(len(names))\n",
        "y = [947, 946, 924, 858, 838]\n",
        "plt.plot(x, y, 'ro-')\n",
        "plt.xticks(x, names, rotation=45)\n",
        "plt.margins(0.08)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4Rr8uyvrYXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "addon_name = {'Addon':['StreamingTV','StreamingMovies','OnlineBackup','TechSupport','OnlineSecurity']}\n",
        "answer = pd.DataFrame(addon_name).round(4)\n",
        "#导出为csv文件\n",
        "answer.to_csv('ID_{}_Q_1_8.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlOPtIuUrYXw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Churn Intervention (24 Marks)\n",
        "\n",
        "The marketing teams wants to know if it is possible to identify customers on social media before they churn and if they can identify potential customers that want to move away from their existing provider. If a customer is identified before they churn then the retention strategy that you developed in Part 1.6 can be applied to stop the customer leaving.\n",
        "\n",
        "The marketing team has outsourced the collection of data and labels. The data was collected from twitter and includes tweets referencing your company and competitors. The data is available in the ``tweets.db`` SQLite file.\n",
        "\n",
        "To achieve the goals of the project you will need to do some EDA to understand the nature of the data and attempt to build a classifier to predict if an individual is likely to churn based on what they wrote in their tweet.\n",
        "\n",
        "## Data\n",
        "\n",
        "### Schema\n",
        "\n",
        "The schema for the ``tweets.db`` file is below:\n",
        "\n",
        "churn\n",
        "\n",
        "| Column  |  Description |\n",
        "|---|---|\n",
        "| tid  | Tweet ID  |\n",
        "| churn  | Churn status  |\n",
        "| set  | Training or Hidden  |\n",
        "\n",
        "tweets\n",
        "\n",
        "| Column  |  Description |\n",
        "|---|---|\n",
        "| tid  | Tweet ID  |\n",
        "| uid  | User ID  |\n",
        "| date  | Datetime of the tweet  |\n",
        "| text  | Content of the tweet  |\n",
        "\n",
        "### Training and Hidden Sets\n",
        "\n",
        "The data has been divided into two sets:\n",
        "\n",
        "| Set  |  Tweets | Target  |\n",
        "|---|---|---|\n",
        "| Training  | Yes  | Yes  |\n",
        "| Hidden  | Yes  | No  |\n",
        "\n",
        "The Churn labels for the training sets has been made available. However the marketing team wants to know how well your classifier will work on future and unseen data before deploying it. They will assess your classification performance on the hidden set."
      ]
    },
    {
      "metadata": {
        "id": "Wtf-JEW6rYXx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5USw0op4rYX1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 How many tweets in the training set contain at least one of the strings \"AT&T\", \"Verizon\" or \"T-Mobile\" (1.5 Marks)\n",
        "\n",
        "Output the number of tweets as an integer to a .txt file. Your search should be invariant to capitilisation.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_1.txt"
      ]
    },
    {
      "metadata": {
        "id": "yS8uDACsrYX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "import sqlite3\n",
        "#导入db文件\n",
        "connection = sqlite3.connect('tweets.db')\n",
        "tweets = pd.read_sql_query('SELECT * FROM tweets', connection)\n",
        "churn = pd.read_sql_query('SELECT * FROM churn', connection)\n",
        "tweets.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "czVMRDbrrYX5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#找到training set\n",
        "train = tweets[churn['set'] =='training']\n",
        "#筛选条件（三个关键词） 竖线表示或者的意思\n",
        "Question2_1 = train[train['text'].str.contains('AT&T|Verizon|T-Mobile',na=False)]\n",
        "#筛选出符合条件的记录，并记录总数量\n",
        "number_tweets = str(len(Question2_1)) \n",
        "#答案为\n",
        "# This will save your answer to a .txt file\n",
        "write_txt(YOURSTUDENTID, \"2_1\", number_tweets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fyZ4vC7arYX7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Find all tweets in the training set containing the strings \"AT&T\", \"Verizon\" and \"switch\" (2.5 Marks)\n",
        "\n",
        "Output the tweets as a two column .csv file with the following format:\n",
        "\n",
        "| tid  |  text |\n",
        "|---|---|\n",
        "| tweet_id1  | text1  |\n",
        "| tweet_id2  | text2  |\n",
        "| tweet_id3  | text3  |\n",
        "| ...  | ...  |\n",
        "\n",
        "The first column should be the tweet id and the second column should be the original text of the tweet. Your search should be invariant to capitilisation.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_2.csv"
      ]
    },
    {
      "metadata": {
        "id": "0wKmzoy-rYX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#找到training set\n",
        "train = tweets[churn['set'] =='training']\n",
        "#筛选条件（三个关键词） 竖线表示或者的意思\n",
        "Question2_1 = train[train['text'].str.contains('AT&T'and 'Verizon'and 'T-Mobile',na=False)]\n",
        "#筛选出符合条件的记录，并记录总数量\n",
        "number_tweets = str(len(Question2_1)) \n",
        "#答案为\n",
        "# This will save your answer to a .txt file\n",
        "write_txt(YOURSTUDENTID, \"2_2\", number_tweets)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R09T5HZTrYX-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3 Identify Churning Customers via Logistic Regression (Total 10 Marks)\n",
        "\n",
        "Train a Logistic Regression Classifier to identify tweets from churning customers\n",
        "\n",
        "Requirements\n",
        "- The original features must be the tweet text data\n",
        "- Use dimension reduction to reduce the dimensionality of the problem. In class you have learnt about PCA. However PCA will not work for TF or TF-IDF data as it is sparse. You must find an alternative method in scikit-learn that works with sparse data.\n",
        "- Maximum of 5 components\n",
        "\n",
        "In Q2.3.5 your marks will be assigned based on your classifiers performance on the hidden set. Make sure you tune your model thoroughly in section Q2.3.3.\n",
        "\n",
        "#### 2.3.1 Transform Features (1.5 Marks)\n",
        "\n",
        "Given the original text data, use an sklearn vectoriser to convert the text to a numeric representation.\n",
        "\n",
        "Output your fitted vectoriser as a pickle file.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_3_1.pickle"
      ]
    },
    {
      "metadata": {
        "id": "Q3yTrEA4rYX_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE 把test转为向量，再用logistic regression\n",
        "#导入相关package\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#定义文本特征提取方法 \n",
        "vectorizer = TfidfVectorizer(stop_words = 'english',\n",
        "                             max_df = 0.90,# 调整数据！出现的最频繁的10%删掉\n",
        "                             min_df = 15) #最好调整 ！ 出现频率最少的删掉， 没有出现15次以上删\n",
        "#fit-transform\n",
        "tfidfs = vectorizer.fit_transform(tweets['text'].fillna('NaN'))\n",
        "#保存结果\n",
        "#在training set 上面32% missclassifaction rate ,可以调整参数，但是不能比这个结果差"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z02NLakXrYYA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code will save your Transformer/Vectoriser object to a file\n",
        "#code 需要改！！！\n",
        "import pickle\n",
        "\n",
        "filename = \"ID_{0}_Q_2_3_1.pickle\".format(YOURSTUDENTID)\n",
        "\n",
        "# MYTRANSFORMEROBJECT must be a sklearn transformer or vectoriser\n",
        "s = pickle.dump(tfidfs, open(filename, 'wb'))# fit 过的model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcCqmRZhrYYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.3.2 Dimension Reduction (1.5 Marks)\n",
        "\n",
        "Reduce the dimensionality of your features to a maximum of 5 components.\n",
        "\n",
        "Output your fitted dimensionality reducing object as a pickle file.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_3_2.pickle"
      ]
    },
    {
      "metadata": {
        "id": "P423RwvMrYYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#检查X PCA 不适合对sparse 降维\n",
        "#导入相关package\n",
        "from sklearn.decomposition import TruncatedSVD #SVD 适合 sparse  matrix\n",
        "#定义降维方法 给小 x 降维\n",
        "tsvd = TruncatedSVD(n_components = 5)\n",
        "x = tfidfs.toarray()\n",
        "\n",
        "#fit-transform\n",
        "X_tsvd = tsvd.fit(x).transform(x)\n",
        "#保存结果\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xGmU7OkrYYF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code will save your Dimensionality Reducer object to a file\n",
        "import pickle\n",
        "\n",
        "filename = \"ID_{0}_Q_2_3_2.pickle\".format(YOURSTUDENTID)\n",
        "\n",
        "# MYREDUCEROBJECT must be a valid dimensionality reducer from sklearn\n",
        "s = pickle.dump(X_tsvd, open(filename, 'wb'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rd8_Rj-1rYYI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.3.3 Tuning (2 Marks)\n",
        "\n",
        "Tune your model hyper-parameters for best performance. Make sure to tune thoroughly!\n",
        "\n",
        "Output your fitted GridSearchCV or RandomisedSearchCV object as a pickle file.\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_3_3.pickle"
      ]
    },
    {
      "metadata": {
        "id": "vijhwfjmrYYJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#3.3-3,5 建立 logistic regression grid每一个网格都是试一试，看哪一loss 最少，只把最重要feature 筛选出来，降低模型复杂程度\n",
        "# C 指的是 ，不要那么多feture, c 越大，越不容忍overfiting ,  对overfit de 容忍度"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqJZEvyBrYYM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#write your code here\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "#定义需要调整的参数，以及合理取值的范围\n",
        "C_range = np.power(10.0, np.arange(-5, 5)) #改range 10的-5次方， 10的5次方， range要改！！！\n",
        "parameters = {'C': C_range}\n",
        "clf = GridSearchCV(LogisticRegression(class_weight = 'balanced'), # y=0 y=1比重完全不同，要设 balance  \n",
        "                   parameters, cv = 5)# cross validation = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UoIa33ehrYYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code will save your GridSearchCV or RandomisedSearchCV to a file\n",
        "import pickle\n",
        "\n",
        "filename = \"ID_{0}_Q_2_3_3.pickle\".format(YOURSTUDENTID)\n",
        "\n",
        "# MYGRIDSEARCHOBJECT must be GridSearchCV or RandomisedSearchCV\n",
        "s = pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5pPAhAw-rYYQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a93ceIRwrYYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.3.4 Output Model (1 Marks)\n",
        "\n",
        "Output your trained logistic regression model as a pickle file. In the next part you will be competing against other students. So make sure you tune your model as best you can!\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_3_4.pickle"
      ]
    },
    {
      "metadata": {
        "id": "dqHUAhFfrYYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 879 之后是training ,之前是hidden\n",
        "# WRITE YOUR CODE HERE\n",
        "X = X_tsvd[879:]  \n",
        "y = churn['churn'][879:]\n",
        "# y = churn[churn['set'] == 'training']['churn']\n",
        "# 带入x,y 的2.3.3 的模型中\n",
        "clf.fit(X,y)\n",
        "clf.best_estimator_\n",
        "#保存结果  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9XqtSUMrYYU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This code will save your LogisticRegression to a file\n",
        "import pickle\n",
        "\n",
        "filename = \"ID_{0}_Q_2_3_4.pickle\".format(YOURSTUDENTID)\n",
        "\n",
        "# MYLOGISTICREGRESSION must be of type sklearn.linear_model.LogisticRegression\n",
        "s = pickle.dump(X_tsvd, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rlxdU27NrYYV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "im3Ebyd_rYYV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### 2.3.5 Predicting Churn for the Hidden Customers (4 Marks)\n",
        "\n",
        "We will assign marks to this question based on the relative performance of each students classifier. You must try and tune your classifier in Question 2.3 as best you can!\n",
        "\n",
        "Output your predictions as a two column .csv file with the following format:\n",
        "\n",
        "| tid  |  Churn |\n",
        "|---|---|\n",
        "| tweet_id1  | 0  |\n",
        "| tweet_id2  | 1  |\n",
        "| tweet_id3  | 0  |\n",
        "| ...  | ...  |\n",
        "\n",
        "where pred1 is the predicted class i.e. 1 is \"Churn\" and 0 is \"Not churn\".\n",
        "\n",
        "FILENAME: ID_STUDENTID_Q_2_3_5.csv"
      ]
    },
    {
      "metadata": {
        "id": "B6O-JpZDrYYW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "#定义X_test\n",
        "X_test = X_tsvd[:879]\n",
        "#带入X_test 的2.3.4的最优模型中\n",
        "#预测得到 y_hat\n",
        "y_pred = clf.predict(X_test)\n",
        "#保存结果到dataframe 中\n",
        "answer = pd.DataFrame({'tid': churn[churn['set']=='hidden']['tid'],\n",
        "                      'Churn': y_pred.astype(int)})\n",
        "#输出结果为csv  文件\n",
        "\n",
        "answer.to_csv('ID_{}_Q_2_3_5.csv'.format(YOURSTUDENTID), index=False)\n",
        "#记得去掉index\n",
        "answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5sSEIhf4rYYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eLm_OQVPrYYb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.4 Prediction Competition (Total 10 Marks)\n",
        "\n",
        "We will assign marks to this question based on the relative performance of each students classifier.\n",
        "\n",
        "Your goal is to build the most accurate classification pipeline for the hidden data. You should do your own research to find suitable preprocessing steps and classifier. You are allowed to use **any preprocessing you like and any sklearn compatible classifier** i.e. it must support the following functions:\n",
        "- fit\n",
        "- predict\n",
        "\n",
        "You must output your classifier (as a pickle file) and predictions (as csv) using the format from Question 2.3.4 and 2.3.5.\n",
        "\n",
        "Good luck!\n",
        "\n",
        "FILENAMES:\n",
        "- ID_{0}_Q_2_4_1.pickle\n",
        "- ID_{0}_Q_2_4_1.csv"
      ]
    },
    {
      "metadata": {
        "id": "6w8I6Qt4rYYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#import sklearn.feature_extraction.text as tt\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "vectorizer = TfidfVectorizer(stop_words = 'english', max_df = 0.90, min_df = 15)\n",
        "#fit-transform\n",
        "tfidfs = vectorizer.fit_transform(tweets['text'].fillna('NaN'))\n",
        "tsvd = TruncatedSVD(n_components = 5)\n",
        "x = tfidfs.toarray()\n",
        "\n",
        "#fit-transform\n",
        "X_tsvd = tsvd.fit(x).transform(x)\n",
        "X = X_tsvd[879:]  \n",
        "y = churn['churn'][879:]\n",
        "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
        "clf = clf.fit(X, y)\n",
        "filename = \"ID_{0}_Q_2_4.pickle\".format(YOURSTUDENTID)\n",
        "\n",
        "# MYGRIDSEARCHOBJECT must be GridSearchCV or RandomisedSearchCV\n",
        "s = pickle.dump(clf, open(filename, 'wb'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjCpDNeArYYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}